{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>521H0287 - Văn Công Nguyên Phong</h1>\n",
    "<h1>521H0285 - Phạm Trần Tiến Phát</h1>\n",
    "<h1>521H0302 - Trương Công Thành</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feed Forward Neural Network**\n",
    "\n",
    "A feed forward neural network (FFNN) is one of the two broad types of artificial neural network, characterized by direction of the flow of information between its layers. Its flow is uni-directional, meaning that the information in the model flows in only one direction—forward—from the input nodes, through the hidden nodes (if any) and to the output nodes, without any cycles or loops, in contrast to recurrent neural networks, which have a bi-directional flow. Modern feedforward networks are trained using the backpropagation method and are colloquially referred to as the \"vanilla\" neural networks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.stats import zscore, boxcox\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization, Activation, Input\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "csv_filename = 'data.csv'\n",
    "csv_path = os.path.join(current_directory, \"data\" ,csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>finalWorth</th>\n",
       "      <th>category</th>\n",
       "      <th>personName</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>source</th>\n",
       "      <th>industries</th>\n",
       "      <th>countryOfCitizenship</th>\n",
       "      <th>organization</th>\n",
       "      <th>selfMade</th>\n",
       "      <th>status</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>lastName</th>\n",
       "      <th>firstName</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>residenceStateRegion</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>birthMonth</th>\n",
       "      <th>birthDay</th>\n",
       "      <th>cpi_country</th>\n",
       "      <th>cpi_change_country</th>\n",
       "      <th>gdp_country</th>\n",
       "      <th>gross_tertiary_education_enrollment</th>\n",
       "      <th>gross_primary_education_enrollment_country</th>\n",
       "      <th>life_expectancy_country</th>\n",
       "      <th>tax_revenue_country_country</th>\n",
       "      <th>total_tax_rate_country</th>\n",
       "      <th>population_country</th>\n",
       "      <th>latitude_country</th>\n",
       "      <th>longitude_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>211000</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>74.0</td>\n",
       "      <td>France</td>\n",
       "      <td>Paris</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "      <td>France</td>\n",
       "      <td>LVMH Moët Hennessy Louis Vuitton</td>\n",
       "      <td>False</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>3/5/1949 0:00</td>\n",
       "      <td>Arnault</td>\n",
       "      <td>Bernard</td>\n",
       "      <td>Chairman and CEO</td>\n",
       "      <td>4/4/2023 5:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>110.05</td>\n",
       "      <td>1.1</td>\n",
       "      <td>$2,715,518,274,227</td>\n",
       "      <td>65.6</td>\n",
       "      <td>102.5</td>\n",
       "      <td>82.5</td>\n",
       "      <td>24.2</td>\n",
       "      <td>60.7</td>\n",
       "      <td>67059887.0</td>\n",
       "      <td>46.227638</td>\n",
       "      <td>2.213749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>180000</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>51.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Tesla, SpaceX</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>True</td>\n",
       "      <td>D</td>\n",
       "      <td>M</td>\n",
       "      <td>6/28/1971 0:00</td>\n",
       "      <td>Musk</td>\n",
       "      <td>Elon</td>\n",
       "      <td>CEO</td>\n",
       "      <td>4/4/2023 5:01</td>\n",
       "      <td>Texas</td>\n",
       "      <td>South</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>117.24</td>\n",
       "      <td>7.5</td>\n",
       "      <td>$21,427,700,000,000</td>\n",
       "      <td>88.2</td>\n",
       "      <td>101.8</td>\n",
       "      <td>78.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>36.6</td>\n",
       "      <td>328239523.0</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>-95.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>114000</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>59.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Medina</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Technology</td>\n",
       "      <td>United States</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>True</td>\n",
       "      <td>D</td>\n",
       "      <td>M</td>\n",
       "      <td>1/12/1964 0:00</td>\n",
       "      <td>Bezos</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>Chairman and Founder</td>\n",
       "      <td>4/4/2023 5:01</td>\n",
       "      <td>Washington</td>\n",
       "      <td>West</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>117.24</td>\n",
       "      <td>7.5</td>\n",
       "      <td>$21,427,700,000,000</td>\n",
       "      <td>88.2</td>\n",
       "      <td>101.8</td>\n",
       "      <td>78.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>36.6</td>\n",
       "      <td>328239523.0</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>-95.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>107000</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Larry Ellison</td>\n",
       "      <td>78.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Lanai</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>Technology</td>\n",
       "      <td>United States</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>True</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>8/17/1944 0:00</td>\n",
       "      <td>Ellison</td>\n",
       "      <td>Larry</td>\n",
       "      <td>CTO and Founder</td>\n",
       "      <td>4/4/2023 5:01</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>West</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>117.24</td>\n",
       "      <td>7.5</td>\n",
       "      <td>$21,427,700,000,000</td>\n",
       "      <td>88.2</td>\n",
       "      <td>101.8</td>\n",
       "      <td>78.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>36.6</td>\n",
       "      <td>328239523.0</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>-95.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>106000</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "      <td>Warren Buffett</td>\n",
       "      <td>92.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "      <td>United States</td>\n",
       "      <td>Berkshire Hathaway Inc. (Cl A)</td>\n",
       "      <td>True</td>\n",
       "      <td>D</td>\n",
       "      <td>M</td>\n",
       "      <td>8/30/1930 0:00</td>\n",
       "      <td>Buffett</td>\n",
       "      <td>Warren</td>\n",
       "      <td>CEO</td>\n",
       "      <td>4/4/2023 5:01</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>117.24</td>\n",
       "      <td>7.5</td>\n",
       "      <td>$21,427,700,000,000</td>\n",
       "      <td>88.2</td>\n",
       "      <td>101.8</td>\n",
       "      <td>78.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>36.6</td>\n",
       "      <td>328239523.0</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>-95.712891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  finalWorth               category                personName   age  \\\n",
       "0     1      211000       Fashion & Retail  Bernard Arnault & family  74.0   \n",
       "1     2      180000             Automotive                 Elon Musk  51.0   \n",
       "2     3      114000             Technology                Jeff Bezos  59.0   \n",
       "3     4      107000             Technology             Larry Ellison  78.0   \n",
       "4     5      106000  Finance & Investments            Warren Buffett  92.0   \n",
       "\n",
       "         country    city              source             industries  \\\n",
       "0         France   Paris                LVMH       Fashion & Retail   \n",
       "1  United States  Austin       Tesla, SpaceX             Automotive   \n",
       "2  United States  Medina              Amazon             Technology   \n",
       "3  United States   Lanai              Oracle             Technology   \n",
       "4  United States   Omaha  Berkshire Hathaway  Finance & Investments   \n",
       "\n",
       "  countryOfCitizenship                      organization  selfMade status  \\\n",
       "0               France  LVMH Moët Hennessy Louis Vuitton     False      U   \n",
       "1        United States                             Tesla      True      D   \n",
       "2        United States                            Amazon      True      D   \n",
       "3        United States                            Oracle      True      U   \n",
       "4        United States    Berkshire Hathaway Inc. (Cl A)      True      D   \n",
       "\n",
       "  gender       birthDate lastName firstName                 title  \\\n",
       "0      M   3/5/1949 0:00  Arnault   Bernard      Chairman and CEO   \n",
       "1      M  6/28/1971 0:00     Musk      Elon                   CEO   \n",
       "2      M  1/12/1964 0:00    Bezos      Jeff  Chairman and Founder   \n",
       "3      M  8/17/1944 0:00  Ellison     Larry       CTO and Founder   \n",
       "4      M  8/30/1930 0:00  Buffett    Warren                   CEO   \n",
       "\n",
       "            date       state residenceStateRegion  birthYear  birthMonth  \\\n",
       "0  4/4/2023 5:01         NaN                  NaN     1949.0         3.0   \n",
       "1  4/4/2023 5:01       Texas                South     1971.0         6.0   \n",
       "2  4/4/2023 5:01  Washington                 West     1964.0         1.0   \n",
       "3  4/4/2023 5:01      Hawaii                 West     1944.0         8.0   \n",
       "4  4/4/2023 5:01    Nebraska              Midwest     1930.0         8.0   \n",
       "\n",
       "   birthDay  cpi_country  cpi_change_country           gdp_country  \\\n",
       "0       5.0       110.05                 1.1   $2,715,518,274,227    \n",
       "1      28.0       117.24                 7.5  $21,427,700,000,000    \n",
       "2      12.0       117.24                 7.5  $21,427,700,000,000    \n",
       "3      17.0       117.24                 7.5  $21,427,700,000,000    \n",
       "4      30.0       117.24                 7.5  $21,427,700,000,000    \n",
       "\n",
       "   gross_tertiary_education_enrollment  \\\n",
       "0                                 65.6   \n",
       "1                                 88.2   \n",
       "2                                 88.2   \n",
       "3                                 88.2   \n",
       "4                                 88.2   \n",
       "\n",
       "   gross_primary_education_enrollment_country  life_expectancy_country  \\\n",
       "0                                       102.5                     82.5   \n",
       "1                                       101.8                     78.5   \n",
       "2                                       101.8                     78.5   \n",
       "3                                       101.8                     78.5   \n",
       "4                                       101.8                     78.5   \n",
       "\n",
       "   tax_revenue_country_country  total_tax_rate_country  population_country  \\\n",
       "0                         24.2                    60.7          67059887.0   \n",
       "1                          9.6                    36.6         328239523.0   \n",
       "2                          9.6                    36.6         328239523.0   \n",
       "3                          9.6                    36.6         328239523.0   \n",
       "4                          9.6                    36.6         328239523.0   \n",
       "\n",
       "   latitude_country  longitude_country  \n",
       "0         46.227638           2.213749  \n",
       "1         37.090240         -95.712891  \n",
       "2         37.090240         -95.712891  \n",
       "3         37.090240         -95.712891  \n",
       "4         37.090240         -95.712891  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billionaires = pd.read_csv(csv_path)\n",
    "billionaires.head(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>finalWorth</th>\n",
       "      <th>age</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>birthMonth</th>\n",
       "      <th>birthDay</th>\n",
       "      <th>cpi_country</th>\n",
       "      <th>cpi_change_country</th>\n",
       "      <th>gross_tertiary_education_enrollment</th>\n",
       "      <th>gross_primary_education_enrollment_country</th>\n",
       "      <th>life_expectancy_country</th>\n",
       "      <th>tax_revenue_country_country</th>\n",
       "      <th>total_tax_rate_country</th>\n",
       "      <th>population_country</th>\n",
       "      <th>latitude_country</th>\n",
       "      <th>longitude_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2640.000000</td>\n",
       "      <td>2640.000000</td>\n",
       "      <td>2575.000000</td>\n",
       "      <td>2564.000000</td>\n",
       "      <td>2564.000000</td>\n",
       "      <td>2564.000000</td>\n",
       "      <td>2456.000000</td>\n",
       "      <td>2456.000000</td>\n",
       "      <td>2458.000000</td>\n",
       "      <td>2459.000000</td>\n",
       "      <td>2458.000000</td>\n",
       "      <td>2457.000000</td>\n",
       "      <td>2458.000000</td>\n",
       "      <td>2.476000e+03</td>\n",
       "      <td>2476.000000</td>\n",
       "      <td>2476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1289.159091</td>\n",
       "      <td>4623.787879</td>\n",
       "      <td>65.140194</td>\n",
       "      <td>1957.183307</td>\n",
       "      <td>5.740250</td>\n",
       "      <td>12.099844</td>\n",
       "      <td>127.755204</td>\n",
       "      <td>4.364169</td>\n",
       "      <td>67.225671</td>\n",
       "      <td>102.858520</td>\n",
       "      <td>78.122823</td>\n",
       "      <td>12.546235</td>\n",
       "      <td>43.963344</td>\n",
       "      <td>5.102053e+08</td>\n",
       "      <td>34.903592</td>\n",
       "      <td>12.583156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>739.693726</td>\n",
       "      <td>9834.240939</td>\n",
       "      <td>13.258098</td>\n",
       "      <td>13.282516</td>\n",
       "      <td>3.710085</td>\n",
       "      <td>9.918876</td>\n",
       "      <td>26.452951</td>\n",
       "      <td>3.623763</td>\n",
       "      <td>21.343426</td>\n",
       "      <td>4.710977</td>\n",
       "      <td>3.730099</td>\n",
       "      <td>5.368625</td>\n",
       "      <td>12.145296</td>\n",
       "      <td>5.542447e+08</td>\n",
       "      <td>17.003497</td>\n",
       "      <td>86.762989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1921.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.550000</td>\n",
       "      <td>-1.900000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>84.700000</td>\n",
       "      <td>54.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>3.801900e+04</td>\n",
       "      <td>-40.900557</td>\n",
       "      <td>-106.346771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>659.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1948.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>117.240000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>50.600000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>6.683440e+07</td>\n",
       "      <td>35.861660</td>\n",
       "      <td>-95.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1312.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1957.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>117.240000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>65.600000</td>\n",
       "      <td>101.800000</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>41.200000</td>\n",
       "      <td>3.282395e+08</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>10.451526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1905.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1966.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>125.080000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>88.200000</td>\n",
       "      <td>102.600000</td>\n",
       "      <td>80.900000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>59.100000</td>\n",
       "      <td>1.366418e+09</td>\n",
       "      <td>40.463667</td>\n",
       "      <td>104.195397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2540.000000</td>\n",
       "      <td>211000.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>288.570000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>136.600000</td>\n",
       "      <td>142.100000</td>\n",
       "      <td>84.200000</td>\n",
       "      <td>37.200000</td>\n",
       "      <td>106.300000</td>\n",
       "      <td>1.397715e+09</td>\n",
       "      <td>61.924110</td>\n",
       "      <td>174.885971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rank     finalWorth          age    birthYear   birthMonth  \\\n",
       "count  2640.000000    2640.000000  2575.000000  2564.000000  2564.000000   \n",
       "mean   1289.159091    4623.787879    65.140194  1957.183307     5.740250   \n",
       "std     739.693726    9834.240939    13.258098    13.282516     3.710085   \n",
       "min       1.000000    1000.000000    18.000000  1921.000000     1.000000   \n",
       "25%     659.000000    1500.000000    56.000000  1948.000000     2.000000   \n",
       "50%    1312.000000    2300.000000    65.000000  1957.000000     6.000000   \n",
       "75%    1905.000000    4200.000000    75.000000  1966.000000     9.000000   \n",
       "max    2540.000000  211000.000000   101.000000  2004.000000    12.000000   \n",
       "\n",
       "          birthDay  cpi_country  cpi_change_country  \\\n",
       "count  2564.000000  2456.000000         2456.000000   \n",
       "mean     12.099844   127.755204            4.364169   \n",
       "std       9.918876    26.452951            3.623763   \n",
       "min       1.000000    99.550000           -1.900000   \n",
       "25%       1.000000   117.240000            1.700000   \n",
       "50%      11.000000   117.240000            2.900000   \n",
       "75%      21.000000   125.080000            7.500000   \n",
       "max      31.000000   288.570000           53.500000   \n",
       "\n",
       "       gross_tertiary_education_enrollment  \\\n",
       "count                          2458.000000   \n",
       "mean                             67.225671   \n",
       "std                              21.343426   \n",
       "min                               4.000000   \n",
       "25%                              50.600000   \n",
       "50%                              65.600000   \n",
       "75%                              88.200000   \n",
       "max                             136.600000   \n",
       "\n",
       "       gross_primary_education_enrollment_country  life_expectancy_country  \\\n",
       "count                                 2459.000000              2458.000000   \n",
       "mean                                   102.858520                78.122823   \n",
       "std                                      4.710977                 3.730099   \n",
       "min                                     84.700000                54.300000   \n",
       "25%                                    100.200000                77.000000   \n",
       "50%                                    101.800000                78.500000   \n",
       "75%                                    102.600000                80.900000   \n",
       "max                                    142.100000                84.200000   \n",
       "\n",
       "       tax_revenue_country_country  total_tax_rate_country  \\\n",
       "count                  2457.000000             2458.000000   \n",
       "mean                     12.546235               43.963344   \n",
       "std                       5.368625               12.145296   \n",
       "min                       0.100000                9.900000   \n",
       "25%                       9.600000               36.600000   \n",
       "50%                       9.600000               41.200000   \n",
       "75%                      12.800000               59.100000   \n",
       "max                      37.200000              106.300000   \n",
       "\n",
       "       population_country  latitude_country  longitude_country  \n",
       "count        2.476000e+03       2476.000000        2476.000000  \n",
       "mean         5.102053e+08         34.903592          12.583156  \n",
       "std          5.542447e+08         17.003497          86.762989  \n",
       "min          3.801900e+04        -40.900557        -106.346771  \n",
       "25%          6.683440e+07         35.861660         -95.712891  \n",
       "50%          3.282395e+08         37.090240          10.451526  \n",
       "75%          1.366418e+09         40.463667         104.195397  \n",
       "max          1.397715e+09         61.924110         174.885971  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billionaires.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2640 entries, 0 to 2639\n",
      "Data columns (total 35 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   rank                                        2640 non-null   int64  \n",
      " 1   finalWorth                                  2640 non-null   int64  \n",
      " 2   category                                    2640 non-null   object \n",
      " 3   personName                                  2640 non-null   object \n",
      " 4   age                                         2575 non-null   float64\n",
      " 5   country                                     2602 non-null   object \n",
      " 6   city                                        2568 non-null   object \n",
      " 7   source                                      2640 non-null   object \n",
      " 8   industries                                  2640 non-null   object \n",
      " 9   countryOfCitizenship                        2640 non-null   object \n",
      " 10  organization                                325 non-null    object \n",
      " 11  selfMade                                    2640 non-null   object \n",
      " 12  status                                      2640 non-null   object \n",
      " 13  gender                                      2640 non-null   object \n",
      " 14  birthDate                                   2564 non-null   object \n",
      " 15  lastName                                    2640 non-null   object \n",
      " 16  firstName                                   2637 non-null   object \n",
      " 17  title                                       339 non-null    object \n",
      " 18  date                                        2640 non-null   object \n",
      " 19  state                                       753 non-null    object \n",
      " 20  residenceStateRegion                        747 non-null    object \n",
      " 21  birthYear                                   2564 non-null   float64\n",
      " 22  birthMonth                                  2564 non-null   float64\n",
      " 23  birthDay                                    2564 non-null   float64\n",
      " 24  cpi_country                                 2456 non-null   float64\n",
      " 25  cpi_change_country                          2456 non-null   float64\n",
      " 26  gdp_country                                 2476 non-null   object \n",
      " 27  gross_tertiary_education_enrollment         2458 non-null   float64\n",
      " 28  gross_primary_education_enrollment_country  2459 non-null   float64\n",
      " 29  life_expectancy_country                     2458 non-null   float64\n",
      " 30  tax_revenue_country_country                 2457 non-null   float64\n",
      " 31  total_tax_rate_country                      2458 non-null   float64\n",
      " 32  population_country                          2476 non-null   float64\n",
      " 33  latitude_country                            2476 non-null   float64\n",
      " 34  longitude_country                           2476 non-null   float64\n",
      "dtypes: float64(14), int64(2), object(19)\n",
      "memory usage: 722.0+ KB\n"
     ]
    }
   ],
   "source": [
    "billionaires['selfMade'] = billionaires['selfMade'].astype(\"object\")\n",
    "billionaires.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "organization                                  2315\n",
       "title                                         2301\n",
       "residenceStateRegion                          1893\n",
       "state                                         1887\n",
       "cpi_change_country                             184\n",
       "cpi_country                                    184\n",
       "tax_revenue_country_country                    183\n",
       "total_tax_rate_country                         182\n",
       "life_expectancy_country                        182\n",
       "gross_tertiary_education_enrollment            182\n",
       "gross_primary_education_enrollment_country     181\n",
       "latitude_country                               164\n",
       "population_country                             164\n",
       "gdp_country                                    164\n",
       "longitude_country                              164\n",
       "birthDate                                       76\n",
       "birthYear                                       76\n",
       "birthMonth                                      76\n",
       "birthDay                                        76\n",
       "city                                            72\n",
       "age                                             65\n",
       "country                                         38\n",
       "firstName                                        3\n",
       "lastName                                         0\n",
       "source                                           0\n",
       "category                                         0\n",
       "personName                                       0\n",
       "selfMade                                         0\n",
       "industries                                       0\n",
       "countryOfCitizenship                             0\n",
       "status                                           0\n",
       "gender                                           0\n",
       "date                                             0\n",
       "finalWorth                                       0\n",
       "rank                                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting total of missing values\n",
    "billionaires.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "billionaires.columns\n",
    "# Specifying input and target variables\n",
    "columns_to_drop = ['personName', 'lastName', 'firstName', 'birthYear', 'birthMonth',\n",
    "                   'birthDay', 'birthDate', 'date', 'organization', 'residenceStateRegion', 'state',\n",
    "                   'title']\n",
    "\n",
    "billionaires.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "cat = billionaires.select_dtypes(include=\"object\").columns\n",
    "num = billionaires.select_dtypes(include=['int', 'float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['category', 'country', 'city', 'source', 'industries',\n",
      "       'countryOfCitizenship', 'selfMade', 'status', 'gender', 'gdp_country'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in billionaires.columns:\n",
    "    if i in cat:\n",
    "        billionaires[i] = billionaires[i].fillna(billionaires[i].mode()[0])\n",
    "    else:\n",
    "        avg = billionaires[i].mean()\n",
    "        md = billionaires[i].median()\n",
    "        mod = billionaires[i].mode()\n",
    "\n",
    "        # Predict missing values        \n",
    "        imputer = KNNImputer(n_neighbors=3)\n",
    "        knr = imputer.fit_transform(billionaires[num])\n",
    "\n",
    "        # Choice one values from randomly\n",
    "        rn_index = np.random.choice(3)\n",
    "        bf = billionaires[i].shift(-1).iloc[rn_index]\n",
    "        af = billionaires[i].shift(+1).iloc[rn_index]\n",
    "\n",
    "        n = [avg, md, mod.values[0], bf, af, knr[rn_index][rn_index]]\n",
    "\n",
    "        rn_value = n[rn_index]\n",
    "        rn_value\n",
    "\n",
    "        # Fill data by selected value\n",
    "        billionaires[i] = billionaires[i].fillna(rn_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank                                          0.0\n",
       "finalWorth                                    0.0\n",
       "category                                      0.0\n",
       "age                                           0.0\n",
       "country                                       0.0\n",
       "city                                          0.0\n",
       "source                                        0.0\n",
       "industries                                    0.0\n",
       "countryOfCitizenship                          0.0\n",
       "selfMade                                      0.0\n",
       "status                                        0.0\n",
       "gender                                        0.0\n",
       "cpi_country                                   0.0\n",
       "cpi_change_country                            0.0\n",
       "gdp_country                                   0.0\n",
       "gross_tertiary_education_enrollment           0.0\n",
       "gross_primary_education_enrollment_country    0.0\n",
       "life_expectancy_country                       0.0\n",
       "tax_revenue_country_country                   0.0\n",
       "total_tax_rate_country                        0.0\n",
       "population_country                            0.0\n",
       "latitude_country                              0.0\n",
       "longitude_country                             0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billionaires.isna().sum()/len(billionaires)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank                                          -0.006357\n",
       "finalWorth                                    10.012367\n",
       "age                                           -0.079037\n",
       "cpi_country                                    2.707725\n",
       "cpi_change_country                             4.465587\n",
       "gross_tertiary_education_enrollment           -0.350761\n",
       "gross_primary_education_enrollment_country     2.401476\n",
       "life_expectancy_country                       -1.074991\n",
       "tax_revenue_country_country                    1.673160\n",
       "total_tax_rate_country                         0.265202\n",
       "population_country                             0.944884\n",
       "latitude_country                              -1.810701\n",
       "longitude_country                             -0.146089\n",
       "dtype: float64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billionaires[num].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "billionaires['finalWorth'] = boxcox(billionaires['finalWorth'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_le = {}\n",
    "\n",
    "for i in cat:\n",
    "    dict_le[i] = LabelEncoder()\n",
    "    billionaires[i] = dict_le[i].fit_transform(billionaires[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X = billionaires.drop('selfMade',axis=1)\n",
    "x = scaler.fit_transform(X)\n",
    "y = billionaires['selfMade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn_normal = Sequential([\n",
    "    Dense(128, activation=\"relu\", input_shape=(xtrain.shape[1],)),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "58/58 [==============================] - 1s 5ms/step - loss: 0.5373 - accuracy: 0.6883 - val_loss: 0.4918 - val_accuracy: 0.7033\n",
      "Epoch 2/10\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7543 - val_loss: 0.4829 - val_accuracy: 0.7664\n",
      "Epoch 3/10\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7749 - val_loss: 0.4866 - val_accuracy: 0.7816\n",
      "Epoch 4/10\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7906 - val_loss: 0.4907 - val_accuracy: 0.7702\n",
      "Epoch 5/10\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7998 - val_loss: 0.4850 - val_accuracy: 0.7904\n",
      "Epoch 6/10\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.8047 - val_loss: 0.4929 - val_accuracy: 0.7790\n",
      "Epoch 7/10\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8122 - val_loss: 0.4945 - val_accuracy: 0.7841\n",
      "Epoch 8/10\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8247 - val_loss: 0.4978 - val_accuracy: 0.7778\n",
      "Epoch 9/10\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8323 - val_loss: 0.5064 - val_accuracy: 0.7513\n",
      "Epoch 10/10\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8306 - val_loss: 0.5383 - val_accuracy: 0.7664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129b28fca60>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffnn_normal.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "ffnn_normal.fit(xtrain, ytrain, epochs=10, batch_size=32, validation_data=(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step\n",
      "Confusion Matrix:\n",
      "[[117 134]\n",
      " [ 51 490]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.47      0.56       251\n",
      "           1       0.79      0.91      0.84       541\n",
      "\n",
      "    accuracy                           0.77       792\n",
      "   macro avg       0.74      0.69      0.70       792\n",
      "weighted avg       0.76      0.77      0.75       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ffnn_normal.predict(xtest)\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "cm = confusion_matrix(ytest, y_pred_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "report = classification_report(ytest, y_pred_classes)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ffnn = Sequential([\n",
    "    Dense(128, activation=\"relu\", input_shape=(xtrain.shape[1],), kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    # Dense(128, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(16, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\",kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "58/58 [==============================] - 1s 6ms/step - loss: 1.7931 - accuracy: 0.5931 - val_loss: 1.4296 - val_accuracy: 0.6831\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 1.2534 - accuracy: 0.6970 - val_loss: 1.0487 - val_accuracy: 0.7134\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.9652 - accuracy: 0.7116 - val_loss: 0.8425 - val_accuracy: 0.7715\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 0.7959 - accuracy: 0.7376 - val_loss: 0.7184 - val_accuracy: 0.7790\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.7033 - accuracy: 0.7538 - val_loss: 0.6472 - val_accuracy: 0.7778\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.7516 - val_loss: 0.6084 - val_accuracy: 0.7790\n",
      "Epoch 7/30\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.7565 - val_loss: 0.5765 - val_accuracy: 0.7803\n",
      "Epoch 8/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7652 - val_loss: 0.5542 - val_accuracy: 0.7765\n",
      "Epoch 9/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7668 - val_loss: 0.5421 - val_accuracy: 0.7740\n",
      "Epoch 10/30\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7727 - val_loss: 0.5374 - val_accuracy: 0.7538\n",
      "Epoch 11/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7733 - val_loss: 0.5247 - val_accuracy: 0.7816\n",
      "Epoch 12/30\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7733 - val_loss: 0.5208 - val_accuracy: 0.7816\n",
      "Epoch 13/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7749 - val_loss: 0.5337 - val_accuracy: 0.7664\n",
      "Epoch 14/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7781 - val_loss: 0.5278 - val_accuracy: 0.7639\n",
      "Epoch 15/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7803 - val_loss: 0.5284 - val_accuracy: 0.7639\n",
      "Epoch 16/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7733 - val_loss: 0.5221 - val_accuracy: 0.7601\n",
      "Epoch 17/30\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7879 - val_loss: 0.5248 - val_accuracy: 0.7778\n",
      "Epoch 18/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7911 - val_loss: 0.5173 - val_accuracy: 0.7753\n",
      "Epoch 19/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7917 - val_loss: 0.5258 - val_accuracy: 0.7626\n",
      "Epoch 20/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7868 - val_loss: 0.5232 - val_accuracy: 0.7790\n",
      "Epoch 21/30\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7835 - val_loss: 0.5270 - val_accuracy: 0.7715\n",
      "Epoch 22/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7949 - val_loss: 0.5257 - val_accuracy: 0.7563\n",
      "Epoch 23/30\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7965 - val_loss: 0.5150 - val_accuracy: 0.7677\n",
      "Epoch 24/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7960 - val_loss: 0.5195 - val_accuracy: 0.7715\n",
      "Epoch 25/30\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7922 - val_loss: 0.5231 - val_accuracy: 0.7588\n",
      "Epoch 26/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7955 - val_loss: 0.5229 - val_accuracy: 0.7664\n",
      "Epoch 27/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.8009 - val_loss: 0.5303 - val_accuracy: 0.7689\n",
      "Epoch 28/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.8036 - val_loss: 0.5267 - val_accuracy: 0.7702\n",
      "Epoch 29/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8074 - val_loss: 0.5370 - val_accuracy: 0.7437\n",
      "Epoch 30/30\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.8166 - val_loss: 0.5409 - val_accuracy: 0.7664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129b285d120>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ffnn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Early Stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model_ffnn.fit(xtrain, ytrain, epochs=30, batch_size=32, validation_data=(xtest, ytest) ,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step\n",
      "Confusion Matrix:\n",
      "[[126 125]\n",
      " [ 60 481]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.50      0.58       251\n",
      "           1       0.79      0.89      0.84       541\n",
      "\n",
      "    accuracy                           0.77       792\n",
      "   macro avg       0.74      0.70      0.71       792\n",
      "weighted avg       0.76      0.77      0.76       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_ffnn.predict(xtest)\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "cm = confusion_matrix(ytest, y_pred_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "report = classification_report(ytest, y_pred_classes)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recurrent Neural Network**\n",
    "\n",
    "Recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a time sequence. This allows the network to take temporary action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_normal = Sequential([\n",
    "    LSTM(units=50, input_shape=(22,1)),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "58/58 [==============================] - 3s 22ms/step - loss: 0.6317 - accuracy: 0.6775 - val_loss: 0.5737 - val_accuracy: 0.6831\n",
      "Epoch 2/10\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.5528 - accuracy: 0.6916 - val_loss: 0.5200 - val_accuracy: 0.7184\n",
      "Epoch 3/10\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 0.5263 - accuracy: 0.7067 - val_loss: 0.5081 - val_accuracy: 0.7222\n",
      "Epoch 4/10\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.5202 - accuracy: 0.7127 - val_loss: 0.5013 - val_accuracy: 0.7285\n",
      "Epoch 5/10\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.5158 - accuracy: 0.7224 - val_loss: 0.4988 - val_accuracy: 0.7323\n",
      "Epoch 6/10\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.5136 - accuracy: 0.7256 - val_loss: 0.5004 - val_accuracy: 0.7412\n",
      "Epoch 7/10\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.5138 - accuracy: 0.7224 - val_loss: 0.4950 - val_accuracy: 0.7437\n",
      "Epoch 8/10\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.5078 - accuracy: 0.7343 - val_loss: 0.4966 - val_accuracy: 0.7374\n",
      "Epoch 9/10\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.5043 - accuracy: 0.7316 - val_loss: 0.5015 - val_accuracy: 0.7247\n",
      "Epoch 10/10\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.4988 - accuracy: 0.7440 - val_loss: 0.4991 - val_accuracy: 0.7386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129b4bbd5a0>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_normal.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rnn_normal.fit( xtrain, ytrain, epochs=10, batch_size=32, validation_data=(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 4ms/step\n",
      "Confusion Matrix:\n",
      "[[102 149]\n",
      " [ 58 483]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.41      0.50       251\n",
      "           1       0.76      0.89      0.82       541\n",
      "\n",
      "    accuracy                           0.74       792\n",
      "   macro avg       0.70      0.65      0.66       792\n",
      "weighted avg       0.72      0.74      0.72       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rnn_normal.predict(xtest)\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "cm = confusion_matrix(ytest, y_pred_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "report = classification_report(ytest, y_pred_classes)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the RNN model\n",
    "model_rnn = Sequential([\n",
    "    LSTM(units=50, input_shape=(22,1)),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "116/116 [==============================] - 5s 16ms/step - loss: 0.7183 - accuracy: 0.5904 - val_loss: 0.6517 - val_accuracy: 0.6831\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - 1s 10ms/step - loss: 0.6330 - accuracy: 0.6596 - val_loss: 0.6606 - val_accuracy: 0.7172\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.6061 - accuracy: 0.6780 - val_loss: 0.6109 - val_accuracy: 0.7071\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5831 - accuracy: 0.6861 - val_loss: 0.5648 - val_accuracy: 0.7424\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5628 - accuracy: 0.7002 - val_loss: 0.5272 - val_accuracy: 0.7285\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - 1s 10ms/step - loss: 0.5790 - accuracy: 0.6948 - val_loss: 0.5196 - val_accuracy: 0.7374\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5698 - accuracy: 0.7175 - val_loss: 0.5145 - val_accuracy: 0.7298\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5526 - accuracy: 0.7056 - val_loss: 0.5083 - val_accuracy: 0.7386\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5454 - accuracy: 0.7186 - val_loss: 0.5107 - val_accuracy: 0.7361\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5407 - accuracy: 0.7235 - val_loss: 0.5020 - val_accuracy: 0.7361\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5452 - accuracy: 0.7100 - val_loss: 0.4974 - val_accuracy: 0.7285\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5407 - accuracy: 0.7143 - val_loss: 0.4981 - val_accuracy: 0.7399\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5433 - accuracy: 0.7159 - val_loss: 0.5082 - val_accuracy: 0.7273\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - 1s 10ms/step - loss: 0.5325 - accuracy: 0.7251 - val_loss: 0.4960 - val_accuracy: 0.7462\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5270 - accuracy: 0.7321 - val_loss: 0.4914 - val_accuracy: 0.7412\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5301 - accuracy: 0.7229 - val_loss: 0.4852 - val_accuracy: 0.7437\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5317 - accuracy: 0.7278 - val_loss: 0.5036 - val_accuracy: 0.7374\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - 1s 10ms/step - loss: 0.5273 - accuracy: 0.7305 - val_loss: 0.4797 - val_accuracy: 0.7563\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - 1s 10ms/step - loss: 0.5181 - accuracy: 0.7354 - val_loss: 0.4837 - val_accuracy: 0.7475\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5228 - accuracy: 0.7338 - val_loss: 0.4820 - val_accuracy: 0.7487\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5273 - accuracy: 0.7403 - val_loss: 0.4838 - val_accuracy: 0.7563\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5253 - accuracy: 0.7251 - val_loss: 0.4834 - val_accuracy: 0.7462\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5144 - accuracy: 0.7311 - val_loss: 0.4868 - val_accuracy: 0.7513\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5165 - accuracy: 0.7327 - val_loss: 0.4876 - val_accuracy: 0.7462\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - 1s 10ms/step - loss: 0.5084 - accuracy: 0.7424 - val_loss: 0.4759 - val_accuracy: 0.7525\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5029 - accuracy: 0.7468 - val_loss: 0.4807 - val_accuracy: 0.7475\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5185 - accuracy: 0.7424 - val_loss: 0.4759 - val_accuracy: 0.7614\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5122 - accuracy: 0.7505 - val_loss: 0.4920 - val_accuracy: 0.7538\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5248 - accuracy: 0.7273 - val_loss: 0.4823 - val_accuracy: 0.7487\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5174 - accuracy: 0.7370 - val_loss: 0.4752 - val_accuracy: 0.7588\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.4968 - accuracy: 0.7532 - val_loss: 0.4932 - val_accuracy: 0.7525\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5016 - accuracy: 0.7522 - val_loss: 0.4846 - val_accuracy: 0.7513\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5001 - accuracy: 0.7505 - val_loss: 0.4933 - val_accuracy: 0.7538\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5050 - accuracy: 0.7522 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5071 - accuracy: 0.7397 - val_loss: 0.4937 - val_accuracy: 0.7386\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.5092 - accuracy: 0.7440 - val_loss: 0.4865 - val_accuracy: 0.7487\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.4947 - accuracy: 0.7543 - val_loss: 0.4789 - val_accuracy: 0.7525\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.4909 - accuracy: 0.7570 - val_loss: 0.4826 - val_accuracy: 0.7513\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.4998 - accuracy: 0.7468 - val_loss: 0.4992 - val_accuracy: 0.7462\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.4966 - accuracy: 0.7592 - val_loss: 0.4943 - val_accuracy: 0.7601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129b80f4df0>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile the model\n",
    "model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_rnn.fit(\n",
    "    xtrain, ytrain,\n",
    "    epochs=50, batch_size=16,\n",
    "    validation_data=(xtest, ytest),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 4ms/step\n",
      "Confusion Matrix:\n",
      "[[114 137]\n",
      " [ 54 487]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.45      0.54       251\n",
      "           1       0.78      0.90      0.84       541\n",
      "\n",
      "    accuracy                           0.76       792\n",
      "   macro avg       0.73      0.68      0.69       792\n",
      "weighted avg       0.75      0.76      0.74       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_rnn.predict(xtest)\n",
    "y_pred_classes = np.round(y_pred)\n",
    "\n",
    "cm = confusion_matrix(ytest, y_pred_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "report = classification_report(ytest, y_pred_classes)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
